2020-05-09 21:31:53,506 - INFO - logger set up
2020-05-09 21:31:53,506 - INFO - seed=718
2020-05-09 21:32:17,628 - INFO - logger set up
2020-05-09 21:32:17,629 - INFO - seed=718
2020-05-09 21:34:06,158 - INFO - logger set up
2020-05-09 21:34:06,158 - INFO - seed=718
2020-05-09 21:34:06,158 - INFO - #####
2020-05-09 21:34:06,158 - INFO - #####
2020-05-09 21:34:06,159 - INFO - Starting fold 0 ...
2020-05-09 21:34:06,159 - INFO - #####
2020-05-09 21:34:06,159 - INFO - #####
2020-05-09 21:34:48,182 - INFO - [load csv data] done in 42.02 s
2020-05-09 21:34:48,238 - INFO - [prepare validation data] done in 0.06 s
2020-05-09 21:34:48,238 - INFO - loading configuration file inputs/roberta-base/config.json
2020-05-09 21:34:48,238 - INFO - Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

2020-05-09 21:34:48,239 - INFO - loading weights file inputs/roberta-base/pytorch_model.bin
2020-05-09 21:34:53,888 - INFO - [create model] done in 5.65 s
2020-05-09 21:34:53,889 - INFO - Starting 1 epoch...
2020-05-09 21:38:05,629 - INFO - logger set up
2020-05-09 21:38:05,629 - INFO - seed=718
2020-05-09 21:38:05,629 - INFO - #####
2020-05-09 21:38:05,629 - INFO - #####
2020-05-09 21:38:05,629 - INFO - Starting fold 0 ...
2020-05-09 21:38:05,629 - INFO - #####
2020-05-09 21:38:05,630 - INFO - #####
2020-05-09 21:38:48,228 - INFO - [load csv data] done in 42.6 s
2020-05-09 21:38:48,283 - INFO - [prepare validation data] done in 0.05 s
2020-05-09 21:38:48,283 - INFO - loading configuration file inputs/roberta-base/config.json
2020-05-09 21:38:48,284 - INFO - Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

2020-05-09 21:38:48,284 - INFO - loading weights file inputs/roberta-base/pytorch_model.bin
2020-05-09 21:38:53,869 - INFO - [create model] done in 5.59 s
2020-05-09 21:38:53,869 - INFO - Starting 1 epoch...
2020-05-09 21:41:06,784 - INFO - logger set up
2020-05-09 21:41:06,785 - INFO - seed=718
2020-05-09 21:41:06,785 - INFO - #####
2020-05-09 21:41:06,785 - INFO - #####
2020-05-09 21:41:06,785 - INFO - Starting fold 0 ...
2020-05-09 21:41:06,785 - INFO - #####
2020-05-09 21:41:06,785 - INFO - #####
2020-05-09 21:41:49,070 - INFO - [load csv data] done in 42.29 s
2020-05-09 21:41:49,125 - INFO - [prepare validation data] done in 0.05 s
2020-05-09 21:41:49,126 - INFO - loading configuration file inputs/roberta-base/config.json
2020-05-09 21:41:49,126 - INFO - Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

2020-05-09 21:41:49,127 - INFO - loading weights file inputs/roberta-base/pytorch_model.bin
2020-05-09 21:41:54,722 - INFO - [create model] done in 5.6 s
2020-05-09 21:41:54,722 - INFO - Starting 1 epoch...
2020-05-09 21:44:33,378 - INFO - logger set up
2020-05-09 21:44:33,378 - INFO - seed=718
2020-05-09 21:44:33,378 - INFO - #####
2020-05-09 21:44:33,378 - INFO - #####
2020-05-09 21:44:33,378 - INFO - Starting fold 0 ...
2020-05-09 21:44:33,378 - INFO - #####
2020-05-09 21:44:33,378 - INFO - #####
2020-05-09 21:45:16,887 - INFO - [load csv data] done in 43.51 s
2020-05-09 21:45:16,942 - INFO - [prepare validation data] done in 0.06 s
2020-05-09 21:45:16,943 - INFO - loading configuration file inputs/roberta-base/config.json
2020-05-09 21:45:16,943 - INFO - Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

2020-05-09 21:45:16,944 - INFO - loading weights file inputs/roberta-base/pytorch_model.bin
2020-05-09 21:45:22,595 - INFO - [create model] done in 5.65 s
2020-05-09 21:45:22,595 - INFO - Starting 1 epoch...
2020-05-09 21:47:15,279 - INFO - logger set up
2020-05-09 21:47:15,279 - INFO - seed=718
2020-05-09 21:47:15,280 - INFO - #####
2020-05-09 21:47:15,280 - INFO - #####
2020-05-09 21:47:15,280 - INFO - Starting fold 0 ...
2020-05-09 21:47:15,280 - INFO - #####
2020-05-09 21:47:15,280 - INFO - #####
2020-05-09 21:47:57,445 - INFO - [load csv data] done in 42.17 s
2020-05-09 21:47:57,501 - INFO - [prepare validation data] done in 0.06 s
2020-05-09 21:47:57,501 - INFO - loading configuration file inputs/roberta-base/config.json
2020-05-09 21:47:57,502 - INFO - Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

2020-05-09 21:47:57,502 - INFO - loading weights file inputs/roberta-base/pytorch_model.bin
2020-05-09 21:48:03,107 - INFO - [create model] done in 5.61 s
2020-05-09 21:48:03,107 - INFO - Starting 1 epoch...
2020-05-09 21:50:17,784 - INFO - logger set up
2020-05-09 21:50:17,784 - INFO - seed=718
2020-05-09 21:50:17,784 - INFO - #####
2020-05-09 21:50:17,785 - INFO - #####
2020-05-09 21:50:17,785 - INFO - Starting fold 0 ...
2020-05-09 21:50:17,785 - INFO - #####
2020-05-09 21:50:17,785 - INFO - #####
2020-05-09 21:51:00,409 - INFO - [load csv data] done in 42.62 s
2020-05-09 21:51:00,464 - INFO - [prepare validation data] done in 0.05 s
2020-05-09 21:51:00,465 - INFO - loading configuration file inputs/roberta-base/config.json
2020-05-09 21:51:00,465 - INFO - Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

2020-05-09 21:51:00,466 - INFO - loading weights file inputs/roberta-base/pytorch_model.bin
2020-05-09 21:51:06,115 - INFO - [create model] done in 5.65 s
2020-05-09 21:51:06,115 - INFO - Starting 1 epoch...
2020-05-09 22:00:35,944 - INFO - logger set up
2020-05-09 22:00:35,944 - INFO - seed=718
2020-05-09 22:00:35,944 - INFO - #####
2020-05-09 22:00:35,944 - INFO - #####
2020-05-09 22:00:35,944 - INFO - Starting fold 0 ...
2020-05-09 22:00:35,945 - INFO - #####
2020-05-09 22:00:35,945 - INFO - #####
2020-05-09 22:01:19,378 - INFO - [load csv data] done in 43.43 s
2020-05-09 22:01:19,433 - INFO - [prepare validation data] done in 0.05 s
2020-05-09 22:01:19,433 - INFO - loading configuration file inputs/roberta-base/config.json
2020-05-09 22:01:19,434 - INFO - Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

2020-05-09 22:01:19,435 - INFO - loading weights file inputs/roberta-base/pytorch_model.bin
2020-05-09 22:01:25,031 - INFO - [create model] done in 5.6 s
2020-05-09 22:01:25,031 - INFO - Starting 1 epoch...
2020-05-09 22:06:19,503 - INFO - logger set up
2020-05-09 22:06:19,503 - INFO - seed=718
2020-05-09 22:06:19,503 - INFO - #####
2020-05-09 22:06:19,503 - INFO - #####
2020-05-09 22:06:19,503 - INFO - Starting fold 0 ...
2020-05-09 22:06:19,504 - INFO - #####
2020-05-09 22:06:19,504 - INFO - #####
2020-05-09 22:07:01,309 - INFO - [load csv data] done in 41.8 s
2020-05-09 22:07:01,364 - INFO - [prepare validation data] done in 0.05 s
2020-05-09 22:07:01,364 - INFO - loading configuration file inputs/roberta-base/config.json
2020-05-09 22:07:01,365 - INFO - Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

2020-05-09 22:07:01,365 - INFO - loading weights file inputs/roberta-base/pytorch_model.bin
2020-05-09 22:07:06,973 - INFO - [create model] done in 5.61 s
2020-05-09 22:07:06,973 - INFO - Starting 1 epoch...
2020-05-09 22:37:07,024 - INFO - logger set up
2020-05-09 22:37:07,024 - INFO - seed=718
2020-05-09 22:37:07,024 - INFO - #####
2020-05-09 22:37:07,024 - INFO - #####
2020-05-09 22:37:07,024 - INFO - Starting fold 0 ...
2020-05-09 22:37:07,024 - INFO - #####
2020-05-09 22:37:07,024 - INFO - #####
2020-05-09 22:37:50,707 - INFO - [load csv data] done in 43.68 s
2020-05-09 22:37:50,763 - INFO - [prepare validation data] done in 0.06 s
2020-05-09 22:37:50,763 - INFO - loading configuration file inputs/roberta-base/config.json
2020-05-09 22:37:50,764 - INFO - Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

2020-05-09 22:37:50,764 - INFO - loading weights file inputs/roberta-base/pytorch_model.bin
2020-05-09 22:37:56,403 - INFO - [create model] done in 5.64 s
2020-05-09 22:37:56,403 - INFO - Starting 1 epoch...
2020-05-09 22:46:59,978 - INFO - logger set up
2020-05-09 22:46:59,978 - INFO - seed=718
2020-05-09 22:46:59,978 - INFO - #####
2020-05-09 22:46:59,978 - INFO - #####
2020-05-09 22:46:59,978 - INFO - Starting fold 0 ...
2020-05-09 22:46:59,978 - INFO - #####
2020-05-09 22:46:59,978 - INFO - #####
2020-05-09 22:47:27,895 - INFO - [load csv data] done in 27.92 s
2020-05-09 22:47:27,950 - INFO - [prepare validation data] done in 0.06 s
2020-05-09 22:47:27,950 - INFO - loading configuration file inputs/roberta-base/config.json
2020-05-09 22:47:27,951 - INFO - Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

2020-05-09 22:47:27,952 - INFO - loading weights file inputs/roberta-base/pytorch_model.bin
2020-05-09 22:47:33,552 - INFO - [create model] done in 5.6 s
2020-05-09 22:47:33,552 - INFO - Starting 1 epoch...
2020-05-09 22:52:52,595 - INFO - logger set up
2020-05-09 22:52:52,596 - INFO - seed=718
2020-05-09 22:52:52,596 - INFO - #####
2020-05-09 22:52:52,596 - INFO - #####
2020-05-09 22:52:52,596 - INFO - Starting fold 0 ...
2020-05-09 22:52:52,596 - INFO - #####
2020-05-09 22:52:52,596 - INFO - #####
2020-05-09 22:53:20,433 - INFO - [load csv data] done in 27.84 s
2020-05-09 22:53:20,487 - INFO - [prepare validation data] done in 0.05 s
2020-05-09 22:53:20,488 - INFO - loading configuration file inputs/roberta-base/config.json
2020-05-09 22:53:20,488 - INFO - Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

2020-05-09 22:53:20,489 - INFO - loading weights file inputs/roberta-base/pytorch_model.bin
2020-05-09 22:53:26,092 - INFO - [create model] done in 5.6 s
2020-05-09 22:53:26,092 - INFO - Starting 1 epoch...
2020-05-09 23:05:33,357 - INFO - logger set up
2020-05-09 23:05:33,357 - INFO - seed=718
2020-05-09 23:05:33,357 - INFO - #####
2020-05-09 23:05:33,358 - INFO - #####
2020-05-09 23:05:33,358 - INFO - Starting fold 0 ...
2020-05-09 23:05:33,358 - INFO - #####
2020-05-09 23:05:33,358 - INFO - #####
2020-05-09 23:06:58,596 - INFO - logger set up
2020-05-09 23:06:58,596 - INFO - seed=718
2020-05-09 23:06:58,596 - INFO - #####
2020-05-09 23:06:58,596 - INFO - #####
2020-05-09 23:06:58,596 - INFO - Starting fold 0 ...
2020-05-09 23:06:58,596 - INFO - #####
2020-05-09 23:06:58,596 - INFO - #####
2020-05-09 23:07:28,995 - INFO - [load csv data] done in 30.4 s
2020-05-09 23:07:29,056 - INFO - [prepare validation data] done in 0.06 s
2020-05-09 23:07:29,056 - INFO - loading configuration file inputs/roberta-base/config.json
2020-05-09 23:07:29,056 - INFO - Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

2020-05-09 23:07:29,057 - INFO - loading weights file inputs/roberta-base/pytorch_model.bin
2020-05-09 23:07:34,744 - INFO - [create model] done in 5.69 s
2020-05-09 23:07:34,744 - INFO - Starting 1 epoch...
2020-05-09 23:21:47,017 - INFO - logger set up
2020-05-09 23:21:47,018 - INFO - seed=718
2020-05-09 23:21:47,018 - INFO - #####
2020-05-09 23:21:47,018 - INFO - #####
2020-05-09 23:21:47,018 - INFO - Starting fold 0 ...
2020-05-09 23:21:47,018 - INFO - #####
2020-05-09 23:21:47,018 - INFO - #####
2020-05-09 23:22:17,830 - INFO - [load csv data] done in 30.81 s
2020-05-09 23:22:17,885 - INFO - [prepare validation data] done in 0.05 s
2020-05-09 23:22:17,885 - INFO - loading configuration file inputs/roberta-base/config.json
2020-05-09 23:22:17,886 - INFO - Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

2020-05-09 23:22:17,886 - INFO - loading weights file inputs/roberta-base/pytorch_model.bin
2020-05-09 23:22:23,547 - INFO - [create model] done in 5.66 s
2020-05-09 23:22:23,548 - INFO - Starting 1 epoch...
2020-05-09 23:34:50,218 - INFO - logger set up
2020-05-09 23:34:50,218 - INFO - seed=718
2020-05-09 23:34:50,218 - INFO - #####
2020-05-09 23:34:50,218 - INFO - #####
2020-05-09 23:34:50,219 - INFO - Starting fold 0 ...
2020-05-09 23:34:50,219 - INFO - #####
2020-05-09 23:34:50,219 - INFO - #####
2020-05-09 23:35:20,499 - INFO - [load csv data] done in 30.28 s
2020-05-09 23:35:20,554 - INFO - [prepare validation data] done in 0.05 s
2020-05-09 23:35:20,555 - INFO - loading configuration file inputs/roberta-base/config.json
2020-05-09 23:35:20,555 - INFO - Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

2020-05-09 23:35:20,556 - INFO - loading weights file inputs/roberta-base/pytorch_model.bin
2020-05-09 23:35:26,212 - INFO - [create model] done in 5.66 s
2020-05-09 23:35:26,212 - INFO - Starting 1 epoch...
2020-05-09 23:41:11,149 - INFO - Jaccard Score = 0.672235361245527
2020-05-09 23:41:11,367 - INFO - save model at score=0.672235361245527 on epoch=1
2020-05-09 23:41:11,367 - INFO - Starting 2 epoch...
2020-05-09 23:47:00,695 - INFO - Jaccard Score = 0.6738998057689441
2020-05-09 23:47:00,998 - INFO - save model at score=0.6738998057689441 on epoch=2
2020-05-09 23:47:00,998 - INFO - Starting 3 epoch...
2020-05-09 23:52:49,568 - INFO - Jaccard Score = 0.6741817683592954
2020-05-09 23:52:49,871 - INFO - save model at score=0.6741817683592954 on epoch=3
2020-05-09 23:52:49,871 - INFO - Starting 4 epoch...
2020-05-09 23:58:38,398 - INFO - Jaccard Score = 0.6757474758837414
2020-05-09 23:58:38,705 - INFO - save model at score=0.6757474758837414 on epoch=4
2020-05-09 23:58:38,705 - INFO - Starting 5 epoch...
2020-05-10 00:04:27,051 - INFO - Jaccard Score = 0.6668947803408284
2020-05-10 00:04:27,051 - INFO - best score is not updated while 1 epochs of training
2020-05-10 00:04:27,051 - INFO - Starting 6 epoch...
2020-05-10 00:10:15,023 - INFO - Jaccard Score = 0.6651124401802087
2020-05-10 00:10:15,023 - INFO - best score is not updated while 2 epochs of training
2020-05-10 00:10:15,024 - INFO - Starting 7 epoch...
2020-05-10 00:16:03,259 - INFO - Jaccard Score = 0.6654795493536643
2020-05-10 00:16:03,259 - INFO - best score is not updated while 3 epochs of training
2020-05-10 00:16:03,260 - INFO - Early Stopping
2020-05-10 00:16:03,260 - INFO - best score=0.6757474758837414 on epoch=4
2020-05-10 00:16:03,260 - INFO - [training loop] done in 2437.05 s
2020-05-10 00:16:03,262 - INFO - #####
2020-05-10 00:16:03,262 - INFO - #####
2020-05-10 00:16:03,262 - INFO - Starting fold 1 ...
2020-05-10 00:16:03,262 - INFO - #####
2020-05-10 00:16:03,262 - INFO - #####
2020-05-10 00:16:33,529 - INFO - [load csv data] done in 30.27 s
2020-05-10 00:16:33,584 - INFO - [prepare validation data] done in 0.05 s
2020-05-10 00:16:33,584 - INFO - loading configuration file inputs/roberta-base/config.json
2020-05-10 00:16:33,585 - INFO - Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

2020-05-10 00:16:33,585 - INFO - loading weights file inputs/roberta-base/pytorch_model.bin
2020-05-10 00:16:35,904 - INFO - [create model] done in 2.32 s
2020-05-10 00:16:35,904 - INFO - Starting 1 epoch...
2020-05-10 00:22:25,780 - INFO - Jaccard Score = 0.6658111419218534
2020-05-10 00:22:25,997 - INFO - save model at score=0.6658111419218534 on epoch=1
2020-05-10 00:22:25,998 - INFO - Starting 2 epoch...
2020-05-10 00:28:14,971 - INFO - Jaccard Score = 0.6721320550593214
2020-05-10 00:28:15,266 - INFO - save model at score=0.6721320550593214 on epoch=2
2020-05-10 00:28:15,266 - INFO - Starting 3 epoch...
2020-05-10 00:34:03,768 - INFO - Jaccard Score = 0.6774425712659906
2020-05-10 00:34:04,064 - INFO - save model at score=0.6774425712659906 on epoch=3
2020-05-10 00:34:04,064 - INFO - Starting 4 epoch...
2020-05-10 00:39:52,470 - INFO - Jaccard Score = 0.6742940390600729
2020-05-10 00:39:52,470 - INFO - best score is not updated while 1 epochs of training
2020-05-10 00:39:52,470 - INFO - Starting 5 epoch...
2020-05-10 00:45:40,864 - INFO - Jaccard Score = 0.6751170838608401
2020-05-10 00:45:40,864 - INFO - best score is not updated while 2 epochs of training
2020-05-10 00:45:40,864 - INFO - Starting 6 epoch...
2020-05-10 00:51:29,031 - INFO - Jaccard Score = 0.6679478146679259
2020-05-10 00:51:29,031 - INFO - best score is not updated while 3 epochs of training
2020-05-10 00:51:29,031 - INFO - Early Stopping
2020-05-10 00:51:29,031 - INFO - best score=0.6774425712659906 on epoch=3
2020-05-10 00:51:29,031 - INFO - [training loop] done in 2093.13 s
2020-05-10 00:51:29,034 - INFO - #####
2020-05-10 00:51:29,034 - INFO - #####
2020-05-10 00:51:29,034 - INFO - Starting fold 2 ...
2020-05-10 00:51:29,034 - INFO - #####
2020-05-10 00:51:29,034 - INFO - #####
2020-05-10 00:51:59,313 - INFO - [load csv data] done in 30.28 s
2020-05-10 00:51:59,372 - INFO - [prepare validation data] done in 0.06 s
2020-05-10 00:51:59,373 - INFO - loading configuration file inputs/roberta-base/config.json
2020-05-10 00:51:59,373 - INFO - Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

2020-05-10 00:51:59,373 - INFO - loading weights file inputs/roberta-base/pytorch_model.bin
2020-05-10 00:52:01,639 - INFO - [create model] done in 2.27 s
2020-05-10 00:52:01,639 - INFO - Starting 1 epoch...
2020-05-10 00:57:51,985 - INFO - Jaccard Score = 0.6570955002259262
2020-05-10 00:57:52,202 - INFO - save model at score=0.6570955002259262 on epoch=1
2020-05-10 00:57:52,202 - INFO - Starting 2 epoch...
2020-05-10 01:03:41,654 - INFO - Jaccard Score = 0.6806405618182312
2020-05-10 01:03:41,948 - INFO - save model at score=0.6806405618182312 on epoch=2
2020-05-10 01:03:41,948 - INFO - Starting 3 epoch...
2020-05-10 01:09:31,411 - INFO - Jaccard Score = 0.6753607761850192
2020-05-10 01:09:31,411 - INFO - best score is not updated while 1 epochs of training
2020-05-10 01:09:31,411 - INFO - Starting 4 epoch...
2020-05-10 01:15:20,766 - INFO - Jaccard Score = 0.6793395148106163
2020-05-10 01:15:20,766 - INFO - best score is not updated while 2 epochs of training
2020-05-10 01:15:20,766 - INFO - Starting 5 epoch...
2020-05-10 01:21:09,740 - INFO - Jaccard Score = 0.6719513022072581
2020-05-10 01:21:09,740 - INFO - best score is not updated while 3 epochs of training
2020-05-10 01:21:09,740 - INFO - Early Stopping
2020-05-10 01:21:09,741 - INFO - best score=0.6806405618182312 on epoch=2
2020-05-10 01:21:09,741 - INFO - [training loop] done in 1748.1 s
2020-05-10 01:21:09,743 - INFO - #####
2020-05-10 01:21:09,743 - INFO - #####
2020-05-10 01:21:09,743 - INFO - Starting fold 3 ...
2020-05-10 01:21:09,743 - INFO - #####
2020-05-10 01:21:09,743 - INFO - #####
2020-05-10 01:21:39,896 - INFO - [load csv data] done in 30.15 s
2020-05-10 01:21:39,950 - INFO - [prepare validation data] done in 0.05 s
2020-05-10 01:21:39,951 - INFO - loading configuration file inputs/roberta-base/config.json
2020-05-10 01:21:39,951 - INFO - Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

2020-05-10 01:21:39,952 - INFO - loading weights file inputs/roberta-base/pytorch_model.bin
2020-05-10 01:21:42,120 - INFO - [create model] done in 2.17 s
2020-05-10 01:21:42,120 - INFO - Starting 1 epoch...
2020-05-10 01:27:33,176 - INFO - Jaccard Score = 0.6651364013605198
2020-05-10 01:27:33,390 - INFO - save model at score=0.6651364013605198 on epoch=1
2020-05-10 01:27:33,391 - INFO - Starting 2 epoch...
2020-05-10 01:33:22,409 - INFO - Jaccard Score = 0.6774362727054636
2020-05-10 01:33:22,705 - INFO - save model at score=0.6774362727054636 on epoch=2
2020-05-10 01:33:22,705 - INFO - Starting 3 epoch...
2020-05-10 01:39:11,663 - INFO - Jaccard Score = 0.6797441346857374
2020-05-10 01:39:11,958 - INFO - save model at score=0.6797441346857374 on epoch=3
2020-05-10 01:39:11,959 - INFO - Starting 4 epoch...
2020-05-10 01:45:01,167 - INFO - Jaccard Score = 0.6658978502853528
2020-05-10 01:45:01,167 - INFO - best score is not updated while 1 epochs of training
2020-05-10 01:45:01,167 - INFO - Starting 5 epoch...
2020-05-10 01:50:50,680 - INFO - Jaccard Score = 0.671351958962116
2020-05-10 01:50:50,680 - INFO - best score is not updated while 2 epochs of training
2020-05-10 01:50:50,680 - INFO - Starting 6 epoch...
2020-05-10 01:56:40,036 - INFO - Jaccard Score = 0.6696424415807076
2020-05-10 01:56:40,037 - INFO - best score is not updated while 3 epochs of training
2020-05-10 01:56:40,037 - INFO - Early Stopping
2020-05-10 01:56:40,037 - INFO - best score=0.6797441346857374 on epoch=3
2020-05-10 01:56:40,037 - INFO - [training loop] done in 2097.92 s
2020-05-10 01:56:40,039 - INFO - #####
2020-05-10 01:56:40,039 - INFO - #####
2020-05-10 01:56:40,039 - INFO - Starting fold 4 ...
2020-05-10 01:56:40,039 - INFO - #####
2020-05-10 01:56:40,039 - INFO - #####
2020-05-10 01:57:10,108 - INFO - [load csv data] done in 30.07 s
2020-05-10 01:57:10,163 - INFO - [prepare validation data] done in 0.05 s
2020-05-10 01:57:10,163 - INFO - loading configuration file inputs/roberta-base/config.json
2020-05-10 01:57:10,164 - INFO - Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

2020-05-10 01:57:10,164 - INFO - loading weights file inputs/roberta-base/pytorch_model.bin
2020-05-10 01:57:12,339 - INFO - [create model] done in 2.18 s
2020-05-10 01:57:12,339 - INFO - Starting 1 epoch...
2020-05-10 02:03:04,109 - INFO - Jaccard Score = 0.6761271865283015
2020-05-10 02:03:04,328 - INFO - save model at score=0.6761271865283015 on epoch=1
2020-05-10 02:03:04,328 - INFO - Starting 2 epoch...
2020-05-10 02:08:53,916 - INFO - Jaccard Score = 0.671674077760707
2020-05-10 02:08:53,916 - INFO - best score is not updated while 1 epochs of training
2020-05-10 02:08:53,916 - INFO - Starting 3 epoch...
2020-05-10 02:14:43,342 - INFO - Jaccard Score = 0.6782765172207664
2020-05-10 02:14:43,640 - INFO - save model at score=0.6782765172207664 on epoch=3
2020-05-10 02:14:43,641 - INFO - Starting 4 epoch...
2020-05-10 02:20:33,272 - INFO - Jaccard Score = 0.6788274778128262
2020-05-10 02:20:33,574 - INFO - save model at score=0.6788274778128262 on epoch=4
2020-05-10 02:20:33,574 - INFO - Starting 5 epoch...
2020-05-10 02:26:23,584 - INFO - Jaccard Score = 0.6747997706111105
2020-05-10 02:26:23,584 - INFO - best score is not updated while 1 epochs of training
2020-05-10 02:26:23,585 - INFO - Starting 6 epoch...
2020-05-10 02:32:13,349 - INFO - Jaccard Score = 0.671308524711909
2020-05-10 02:32:13,350 - INFO - best score is not updated while 2 epochs of training
2020-05-10 02:32:13,350 - INFO - Starting 7 epoch...
2020-05-10 02:38:02,844 - INFO - Jaccard Score = 0.6666898316306651
2020-05-10 02:38:02,844 - INFO - best score is not updated while 3 epochs of training
2020-05-10 02:38:02,844 - INFO - Early Stopping
2020-05-10 02:38:02,844 - INFO - best score=0.6788274778128262 on epoch=4
2020-05-10 02:38:02,844 - INFO - [training loop] done in 2450.51 s
2020-05-10 10:29:09,134 - INFO - logger set up
2020-05-10 10:29:09,134 - INFO - seed=718
2020-05-10 10:29:09,134 - INFO - #####
2020-05-10 10:29:09,135 - INFO - #####
2020-05-10 10:29:09,135 - INFO - Starting fold 0 ...
2020-05-10 10:29:09,135 - INFO - #####
2020-05-10 10:29:09,135 - INFO - #####
